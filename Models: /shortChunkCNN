# Part 1 Feature Extraction
#1.1 import libaries ( not gonna need all of them probably)
import os, sys
import numpy as np
import pandas as pd
import librosa
import IPython.display as ipd
from tqdm import tqdm
import matplotlib.pyplot as plt
import librosa.display
#1.2  Save audio paths and target labels 
# Get the base directory
basedir = os.getcwd()                   # insert our directory 
dirname = basedir+ "/Data/genres_original"

# Create lists for audio paths and labels
for root, dirs, files in os.walk(dirname, topdown=False):
    for filenames in files:
        if filenames.find('.wav') != -1:

            audio_paths.append(os.path.join(root, filenames))
            filenames = filenames.split('.', 1)
            filenames = filenames[0]
            audio_label.append(filenames)
audio_paths = np.array(audio_paths)
audio_label = np.array(audio_label)

# audio_paths.shape
#1.3 Extract features for spectorgram and mel-spectorgam 
# Create empty arrays for the features
AllSpec = np.empty([1000, 1025, 1293])
AllMel = np.empty([1000, 128, 1293])

count = 0

# Create a list for the corrupt indices (idk if this applies to us as we dont have any corrupt files)
bad_index = []
for i in tqdm(range(len(audio_paths))):
    try:

        path = audio_paths[i]
        y, sr = librosa.load(path)
        # For Spectrogram
        X = librosa.stft(y)
        Xdb = librosa.amplitude_to_db(abs(X))
        AllSpec[i] = Xdb
        
        # Mel-Spectrogram 
        M = librosa.feature.melspectrogram(y=y)
        M_db = librosa.power_to_db(M)
        AllMel[i] = M_db

except Exception as e:
        bad_index.append(i)

#1.4  Remove corrupt files - Delete the audio files and labels at the corrupt indices. 
# The features are then converted to float32 data type to save memory usage. 
# After that, we assign the labels numerical values and convert them into categorical data. 
# In the end, we save all the extracted features and their labels into a .npz file.
# When we start the classification task, we can directly load the .npz file to use the features.

# 1.4.1 Delete the features at the corrupt indices
AllSpec = np.delete(AllSpec, bad_index, 0)
AllMel = np.delete(AllMel, bad_index, 0)

# Convert features to float32 
AllSpec = AllSpec.astype(np.float32)
AllMel = AllMel.astype(np.float32)

# Delete audio labels at corrupt indices
audio_label = np.delete(audio_label, bad_index)

# Convert labels from string into numerical value
audio_label[audio_label == ' Deep House'] = 0
audio_label[audio_label == 'Disco Funk'] = 1
audio_label[audio_label == 'Chinese Traditional'] = 2
audio_label[audio_label == 'Reggaeton Pop'] = 3
audio_label[audio_label == 'Keyboard Collection'] = 4
audio_label = [int(i) for i in audio_label]
audio_label = np.array(audio_label)

# Convert numerical data into categorical data
y = tensorflow.keras.utils.to_categorical(audio_label,num_classes = 10, dtype ="int32")

# Save the features and labels as a .npz file
np.savez_compressed(os.getcwd()+"/MusicFeatures.npz", spec= AllSpec, mel= AllMel, mfcc= AllMfcc, zcr= AllZcr, cen= AllCen, chroma= AllChroma, target=y)



# Part-2 Classification 
# 2.1 Import Libaries 
import os, sys, cv2
import seaborn as sn
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
import keras
from keras.models import Sequential, Input,Model, load_model
from keras.layers import Dense, Dropout, Flatten, LSTM
from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D, MaxPool1D, GaussianNoise, GlobalMaxPooling1D
from keras.layers import BatchNormalization
from keras.callbacks import ModelCheckpoint
from keras.layers.advanced_activations import LeakyReLU
import tensorflow
import matplotlib.pyplot as plt
from sklearn.model_selection import KFold

# 2.2  Import npz file, extract the features, and split the train-test data
# load the .npz file of features
f = np.load(os.getcwd()+"/MusicFeatures.npz")
S = f['spec']
mfcc = f['mfcc']
mel = f['mel']
chroma = f['chroma']
y = f['target']

# split train-test data
S_train, S_test, mfcc_train, mfcc_test, mel_train, mel_test, chroma_train, chroma_test, y_train, y_test = train_test_split(S, mfcc, mel, chroma, y, test_size= 0.2)

#2.3  Resizing and Reshaping data

# Spectrogram
maximum1 = np.amax(S_train)
S_train = S_train/np.amax(maximum1)
S_test = S_test/np.amax(maximum1)

S_train = S_train.astype(np.float32)
S_test = S_test.astype(np.float32)

N, row, col = S_train.shape
S_train = S_train.reshape((N, row, col, 1))

N, row, col = S_test.shape
S_test = S_test.reshape((N, row, col, 1))
#2.4 Save training and testing features in npz file




